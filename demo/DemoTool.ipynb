{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnwLWZ6SuOw2"
      },
      "source": [
        "# DEMO TOOL TRADITIONAL IRISH MUSIC CLASSIFIER FOR SCORES\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elloza/ITMA-classifier-paper/blob/main/demo/DemoTool.ipynb)\n",
        "\n",
        "\n",
        "⚠️ **YOU MUST SELECT THE PRO EXECUTION ENVIRONMENT TO RUN THE DEMO\n",
        "(Jukemir need a lot of RAM and VRAM)**⚠️\n",
        "\n",
        "\n",
        "This is the demo tool for deploying the traditional Irish music classifier for scores.\n",
        "\n",
        "<!-- Align center and with space in the middle -->\n",
        "<div align=\"center\" style=\"margin: 0px 0px 0px 0px;\">\n",
        "\n",
        "  <a href=\"https://github.com/elloza/DIGIFOLK-USAL-ITMA\" style=\"margin:20px;\">\n",
        "    <img src=\"https://usal.es/files/logo_usal.png\" alt=\"Logo\" width=\"250\" height=\"100\" style=\"margin:10px;padding:20px;\">\n",
        "  </a>\n",
        "\n",
        "  <a href=\"https://github.com/elloza/DIGIFOLK-USAL-ITMA\" style=\"margin:20px;\">\n",
        "    <img src=\"https://www.itma.ie/wp-content/themes/ITMA/images/itma-logo.svg\" alt=\"Logo\" width=\"250\" height=\"100\" style=\"margin:10px;padding:20px;\">\n",
        "  </a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "def clear(message):\n",
        "    clear_output(wait=True)\n",
        "    display(HTML(f'<span style=\"color: green;\">{message}</span>'))\n",
        "\n",
        "clear(\"Completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6oAjRcD14zWY",
        "outputId": "abf274a7-33b5-4954-be40-f8449ac2ce80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"color: green;\">Completed</span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WXs73OVYV5G",
        "outputId": "22a7475d-6767-4f08-e149-3891b70b0212"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb 15 10:54:07 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0              23W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone Repository on colab"
      ],
      "metadata": {
        "id": "lTOUVUv2uSlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/elloza/ITMA-classifier-paper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_ayW19FuRSL",
        "outputId": "fca6afb2-722d-4ce8-9439-f5ecae5329b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ITMA-classifier-paper'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 37 (delta 10), reused 31 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (37/37), 9.12 MiB | 19.09 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ITMA-classifier-paper\n",
        "%cd demo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgmPtcleuoGP",
        "outputId": "2ae6cc71-0a14-47d7-8368-b0ec53190fe3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ITMA-classifier-paper\n",
            "/content/ITMA-classifier-paper/demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu8WUlZ1uOw6"
      },
      "source": [
        "## Install all the required libraries\n",
        "\n",
        "This could take some time.⏳"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kjN6sLNDuOw6",
        "outputId": "eb73545e-875c-4ddc-dae0-ecfc96c72045"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"color: green;\">Libraries installed</span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install pycaret\n",
        "!pip install pycaret[full]\n",
        "# install gradio\n",
        "!pip install -U gradio\n",
        "clear(\"Libraries installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Conversion File Libraries"
      ],
      "metadata": {
        "id": "4JZ_nsM3wWqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install midi2audio\n",
        "!sudo apt-get update && sudo apt-get install fluidsynth -y && sudo apt-get install abcmidi -y\n",
        "%pip install git+https://github.com/SpotlightKid/abc2xml\n",
        "clear(\"Converters installed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "O6MUe_lGwWBm",
        "outputId": "cdc962f4-4738-458d-a3b2-7e2218ccd845"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"color: green;\">Converters installed</span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install MERT Dependencies"
      ],
      "metadata": {
        "id": "nhRcpUFC4Qai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jukemir\n",
        "%pip install git+https://github.com/rodrigo-castellon/jukemirlib.git\n",
        "\n",
        "# Mule\n",
        "!sudo apt-get install git-lfs\n",
        "!git clone https://github.com/PandoraMedia/music-audio-representations.git ~/.cache/music-audio-representations\n",
        "%cd ~/.cache/music-audio-representations\n",
        "!git lfs pull\n",
        "%cd\n",
        "%pip install --upgrade pip\n",
        "%pip install \"cython<3.0.0\" wheel && pip install pyyaml==5.4.1 --no-build-isolation\n",
        "%pip install librosa==0.9.2\n",
        "%pip install sxmp-mule\n",
        "\n",
        "# Mert\n",
        "%pip install transformers==4.29.2\n",
        "%pip install datasets\n",
        "%pip install nnAudio==0.3.1\n",
        "%pip uninstall -y tqdm\n",
        "%pip install -U tqdm\n",
        "clear(\"Mule Mert and Jukemir installed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1CqB6KW34Tbq",
        "outputId": "bed85d23-d4d3-4094-e1e9-fecba808e680"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"color: green;\">Mule Mert and Jukemir installed</span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ITMA-classifier-paper/demo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95Lgp1mL6T2a",
        "outputId": "6ae5c4be-745b-4854-f400-7fee56208794"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ITMA-classifier-paper/demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og7DI0qBuOw-"
      },
      "source": [
        "# Execute Gradio from here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jCoG8lruOw-",
        "outputId": "f87ce802-04d3-448b-c864-3a7447a6e7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ITMA-classifier-paper/demo\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4GJ2rnUuOw_"
      },
      "outputs": [],
      "source": [
        "import pycaret\n",
        "from pycaret.classification import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from MusicFileConverter import MusicFileConverter\n",
        "from EmbeddingExtractor import EmbeddingExtractor\n",
        "\n",
        "# GENRES\n",
        "N_GENRES = 15\n",
        "\n",
        "# Definir la carpeta de subidas y asegurarse de que exista\n",
        "uploads_folder = \"./uploads/\"\n",
        "os.makedirs(uploads_folder, exist_ok=True)\n",
        "\n",
        "# LOAD CLASSIFIER\n",
        "classifier = load_model(\"embedding_mert_best_model\")\n",
        "\n",
        "# LOAD EMBEDDING EXTRACTOR (CHANGE THIS TO OTHER MODELS LIKE MULE OR JUKEMIR)\n",
        "extractor = EmbeddingExtractor(\"mert\")\n",
        "\n",
        "print(\"Loaded embedding model: \")\n",
        "print(extractor.embedding_model)\n",
        "\n",
        "# TODO: CHANGE PATHS!\n",
        "converter = MusicFileConverter(abc2xml_path_file=\"./abc2xml.py\", xml2abc_path_file=\"./xml2abc.py\")\n",
        "\n",
        "def process_file(fileobj, folder):\n",
        "    # Asegurarse de que el nombre del archivo no contenga rutas para evitar problemas de seguridad\n",
        "    filename = os.path.basename(fileobj.name)\n",
        "    path = os.path.join(folder, filename)\n",
        "    shutil.copyfile(fileobj.name, path)\n",
        "    return path\n",
        "\n",
        "def transform_file_to_wav(uploaded_file):\n",
        "\n",
        "    print(uploaded_file)\n",
        "\n",
        "    if uploaded_file is None:\n",
        "      raise Exception(\"File is None\")\n",
        "\n",
        "    file_path = process_file(uploaded_file, uploads_folder)\n",
        "\n",
        "    print(\"Fichero escrito:\"+file_path)\n",
        "\n",
        "    # Obtener el nombre del fichero sin extensión\n",
        "    nombre_fichero_sin_extension = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "    wav_file = os.path.join(os.path.dirname(file_path), nombre_fichero_sin_extension + '.wav')\n",
        "\n",
        "    print(wav_file)\n",
        "\n",
        "    # Check if file is abc, mid, or xml\n",
        "    if file_path.endswith(\".abc\"):\n",
        "        # Crear rutas para los archivos .mid y .wav\n",
        "        midi_file = uploads_folder + nombre_fichero_sin_extension + '.mid'\n",
        "        midi_file = converter.abc_to_midi(file_path, midi_file)\n",
        "        wav_file = converter.midi_to_wav(midi_file, wav_file)\n",
        "    elif file_path.endswith(\".mid\"):\n",
        "        wav_file = converter.midi_to_wav(file_path, wav_file)\n",
        "    elif file_path.endswith(\".xml\"):\n",
        "        midi_file = uploads_folder + nombre_fichero_sin_extension + '.mid'\n",
        "        midi_file = converter.xml_to_midi(file_path,midi_file)\n",
        "        wav_file = converter.midi_to_wav(midi_file, wav_file)\n",
        "    else:\n",
        "        raise Exception(\"File format not supported\")\n",
        "\n",
        "    return wav_file\n",
        "\n",
        "def transform_wav_to_embedding_row(wav_file):\n",
        "    # Extract embedding from a music file\n",
        "    embedding = extractor.get_embedding(wav_file)\n",
        "    print(\"Mert embedding: \")\n",
        "    print(embedding)\n",
        "\n",
        "    # Crear nombres de columnas basados en la longitud del embedding\n",
        "    column_names = [f\"embedding_mert_{i}\" for i in range(len(embedding))]\n",
        "\n",
        "    # Convertir el embedding en un dataframe y retornar\n",
        "    embedding_df = pd.DataFrame([embedding], columns=column_names)\n",
        "    return embedding_df\n",
        "\n",
        "def classify_file(uploaded_file):\n",
        "    # Supongamos que nuestro modelo nos da scores para tres clases: A, B y C\n",
        "    # Estos son valores de ejemplo\n",
        "    global classifier\n",
        "    global converter\n",
        "\n",
        "    # 1 - Transform abc, mid, or xml file to wav file\n",
        "    wav_file = transform_file_to_wav(uploaded_file)\n",
        "    print(wav_file)\n",
        "\n",
        "    # 2 - Transform wav file to embedding row with columns embedding_mule_0, embedding_mule__1, etc\n",
        "    df = transform_wav_to_embedding_row(wav_file)\n",
        "\n",
        "    # 3 - Perform the inference\n",
        "    pred = predict_model(classifier, df, raw_score=True)\n",
        "\n",
        "    print(pred)\n",
        "\n",
        "    # Get only the columns called prediction_score_*\n",
        "    pred = pred.filter(regex=\"prediction_score_*\")\n",
        "\n",
        "    print(pred)\n",
        "\n",
        "    # Get pred as a dictionary where keys are the columns names and values are the columns values\n",
        "    pred_dict = pred.to_dict(\"records\")[0]\n",
        "\n",
        "    # Rename the keys of the dictionary to remove the prefix prediction_score_\n",
        "    pred_dict = {key.replace(\"prediction_score_\", \"\"): value for key, value in pred_dict.items()}\n",
        "\n",
        "    return pred_dict\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Logo y título personalizado utilizando HTML\n",
        "title_with_logo = \"\"\"\n",
        "    <div style='text-align: center;'>\n",
        "        <div style='margin-bottom: 10px; font-weight: bold;'>\n",
        "            IRISH TRADITIONAL MUSIC GENRE CLASSIFICATION\n",
        "        </div>\n",
        "        <div style='margin-bottom: 10px; font-weight: regular;'>\n",
        "            Identifying Irish traditional music genres using latent audio representations\n",
        "        </div>\n",
        "        <div style='display: flex; justify-content: space-between; align-items: center;'>\n",
        "            <a href=\"https://github.com/elloza/DIGIFOLK-USAL-ITMA\">\n",
        "                <img src=\"https://usal.es/files/logo_usal.png\" alt=\"Logo\" width=\"150\" height=\"50\" style=\"margin:10px;padding:20px;\">\n",
        "            </a>\n",
        "            <a href=\"https://github.com/elloza/DIGIFOLK-USAL-ITMA\">\n",
        "                <img src=\"https://www.itma.ie/wp-content/themes/ITMA/images/itma-logo.svg\" alt=\"Logo\" width=\"150\" height=\"50\" style=\"margin:10px;padding:20px;\">\n",
        "            </a>\n",
        "            <a href=\"https://github.com/elloza/DIGIFOLK-USAL-ITMA\">\n",
        "                <img src=\"https://cordis.europa.eu/images/logo/logo-ec-es.svg\" alt=\"Logo\" width=\"150\" height=\"50\" style=\"margin:10px;padding:20px;\">\n",
        "            </a>\n",
        "        </div>\n",
        "    </div>\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(title=\"ITMA Classifier\", theme=gr.themes.Default(primary_hue=\"emerald\")) as demo:\n",
        "    iface = gr.Interface(\n",
        "        fn=classify_file,\n",
        "        inputs=gr.File(label=\"Upload .abc, .mid, or .xml file\"),\n",
        "        outputs=gr.Label(num_top_classes=N_GENRES),\n",
        "        live=False,\n",
        "        title=title_with_logo,\n",
        "        allow_flagging=\"never\"\n",
        "    )\n",
        "\n",
        "# Share the demo with a public link\n",
        "demo.launch(share=True, inbrowser=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6lWUgttuOxA"
      },
      "source": [
        "## Execute the application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG2deuVkuOxA"
      },
      "source": [
        "## Deploy Gradio Application"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JUKEMIR\n",
        "\n",
        "Same code but with jukemir\n",
        "\n",
        "This could take some time.⏳ **30 minutes aprox for the first inference (the jukemir models download takes time)**\n"
      ],
      "metadata": {
        "id": "ws2KE-nUhJPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycaret\n",
        "from pycaret.classification import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from MusicFileConverter import MusicFileConverter\n",
        "from EmbeddingExtractor import EmbeddingExtractor\n",
        "\n",
        "# GENRES\n",
        "N_GENRES = 15\n",
        "\n",
        "# Definir la carpeta de subidas y asegurarse de que exista\n",
        "uploads_folder = \"./uploads/\"\n",
        "os.makedirs(uploads_folder, exist_ok=True)\n",
        "\n",
        "# LOAD CLASSIFIER\n",
        "classifier = load_model(\"embedding_jukemir_best_model\")\n",
        "\n",
        "# LOAD EMBEDDING EXTRACTOR (CHANGE THIS TO OTHER MODELS LIKE MULE OR JUKEMIR)\n",
        "extractor = EmbeddingExtractor(\"jukemir\")\n",
        "\n",
        "print(\"Loaded embedding model: \")\n",
        "print(extractor.embedding_model)\n",
        "\n",
        "# TODO: CHANGE PATHS!\n",
        "converter = MusicFileConverter(abc2xml_path_file=\"./abc2xml.py\", xml2abc_path_file=\"./xml2abc.py\")\n",
        "\n",
        "def process_file(fileobj, folder):\n",
        "    # Asegurarse de que el nombre del archivo no contenga rutas para evitar problemas de seguridad\n",
        "    filename = os.path.basename(fileobj.name)\n",
        "    path = os.path.join(folder, filename)\n",
        "    shutil.copyfile(fileobj.name, path)\n",
        "    return path\n",
        "\n",
        "def transform_file_to_wav(uploaded_file):\n",
        "\n",
        "    print(uploaded_file)\n",
        "\n",
        "    if uploaded_file is None:\n",
        "      raise Exception(\"File is None\")\n",
        "\n",
        "    file_path = process_file(uploaded_file, uploads_folder)\n",
        "\n",
        "    print(\"Fichero escrito:\"+file_path)\n",
        "\n",
        "    # Obtener el nombre del fichero sin extensión\n",
        "    nombre_fichero_sin_extension = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "    wav_file = os.path.join(os.path.dirname(file_path), nombre_fichero_sin_extension + '.wav')\n",
        "\n",
        "    print(wav_file)\n",
        "\n",
        "    # Check if file is abc, mid, or xml\n",
        "    if file_path.endswith(\".abc\"):\n",
        "        # Crear rutas para los archivos .mid y .wav\n",
        "        midi_file = uploads_folder + nombre_fichero_sin_extension + '.mid'\n",
        "        midi_file = converter.abc_to_midi(file_path, midi_file)\n",
        "        wav_file = converter.midi_to_wav(midi_file, wav_file)\n",
        "    elif file_path.endswith(\".mid\"):\n",
        "        wav_file = converter.midi_to_wav(file_path, wav_file)\n",
        "    elif file_path.endswith(\".xml\"):\n",
        "        midi_file = uploads_folder + nombre_fichero_sin_extension + '.mid'\n",
        "        midi_file = converter.xml_to_midi(file_path,midi_file)\n",
        "        wav_file = converter.midi_to_wav(midi_file, wav_file)\n",
        "    else:\n",
        "        raise Exception(\"File format not supported\")\n",
        "\n",
        "    return wav_file\n",
        "\n",
        "def transform_wav_to_embedding_row(wav_file):\n",
        "    # Extract embedding from a music file\n",
        "    embedding = extractor.get_embedding(wav_file)\n",
        "    print(\"Jukemir embedding: \")\n",
        "    print(embedding)\n",
        "\n",
        "    # Crear nombres de columnas basados en la longitud del embedding\n",
        "    column_names = [f\"embedding_jukemir_{i}\" for i in range(len(embedding))]\n",
        "\n",
        "    # Convertir el embedding en un dataframe y retornar\n",
        "    embedding_df = pd.DataFrame([embedding], columns=column_names)\n",
        "    return embedding_df\n",
        "\n",
        "def classify_file(uploaded_file):\n",
        "    # Supongamos que nuestro modelo nos da scores para tres clases: A, B y C\n",
        "    # Estos son valores de ejemplo\n",
        "    global classifier\n",
        "    global converter\n",
        "\n",
        "    # 1 - Transform abc, mid, or xml file to wav file\n",
        "    wav_file = transform_file_to_wav(uploaded_file)\n",
        "    print(wav_file)\n",
        "\n",
        "    # 2 - Transform wav file to embedding row with columns embedding_mule_0, embedding_mule__1, etc\n",
        "    df = transform_wav_to_embedding_row(wav_file)\n",
        "\n",
        "    # 3 - Perform the inference\n",
        "    pred = predict_model(classifier, df, raw_score=True)\n",
        "\n",
        "    print(pred)\n",
        "\n",
        "    # Get only the columns called prediction_score_*\n",
        "    pred = pred.filter(regex=\"prediction_score_*\")\n",
        "\n",
        "    print(pred)\n",
        "\n",
        "    # Get pred as a dictionary where keys are the columns names and values are the columns values\n",
        "    pred_dict = pred.to_dict(\"records\")[0]\n",
        "\n",
        "    # Rename the keys of the dictionary to remove the prefix prediction_score_\n",
        "    pred_dict = {key.replace(\"prediction_score_\", \"\"): value for key, value in pred_dict.items()}\n",
        "\n",
        "    return pred_dict\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Logo y título personalizado utilizando HTML\n",
        "title_with_logo = \"\"\"\n",
        "    <div style='text-align: center;'>\n",
        "        <div style='margin-bottom: 10px; font-weight: bold;'>\n",
        "            IRISH TRADITIONAL MUSIC GENRE CLASSIFICATION\n",
        "        </div>\n",
        "        <div style='margin-bottom: 10px; font-weight: regular;'>\n",
        "            Identifying Irish traditional music genres using latent audio representations\n",
        "        </div>\n",
        "        <div style='display: flex; justify-content: space-between; align-items: center;'>\n",
        "            <a href=\"https://github.com/elloza/DIGIFOLK-USAL-ITMA\">\n",
        "                <img src=\"https://usal.es/files/logo_usal.png\" alt=\"Logo\" width=\"150\" height=\"50\" style=\"margin:10px;padding:10px;\">\n",
        "            </a>\n",
        "            <a href=\"https://github.com/elloza/DIGIFOLK-USAL-ITMA\">\n",
        "                <img src=\"https://www.itma.ie/wp-content/themes/ITMA/images/itma-logo.svg\" alt=\"Logo\" width=\"150\" height=\"50\" style=\"margin:10px;padding:10px;\">\n",
        "            </a>\n",
        "            <a href=\"https://github.com/elloza/DIGIFOLK-USAL-ITMA\">\n",
        "                <img src=\"https://cordis.europa.eu/images/logo/logo-ec-es.svg\" alt=\"Logo\" width=\"150\" height=\"50\" style=\"margin:10px;padding:10px;\">\n",
        "            </a>\n",
        "        </div>\n",
        "    </div>\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(title=\"ITMA Classifier\", theme=gr.themes.Default(primary_hue=\"emerald\")) as demo:\n",
        "    iface = gr.Interface(\n",
        "        fn=classify_file,\n",
        "        inputs=gr.File(label=\"Upload .abc, .mid, or .xml file\"),\n",
        "        outputs=gr.Label(num_top_classes=N_GENRES),\n",
        "        live=False,\n",
        "        title=title_with_logo,\n",
        "        allow_flagging=\"never\"\n",
        "    )\n",
        "\n",
        "# Share the demo with a public link\n",
        "demo.launch(share=True, inbrowser=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "4vlZBIefhMKu",
        "outputId": "21f6844b-82a5-48ed-f625-36300c43142b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformation Pipeline and Model Successfully Loaded\n",
            "Loaded embedding model: \n",
            "<EmbeddingExtractor.Jukemir object at 0x79edd8a0e080>\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://2fe059c8e7d2905b92.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2fe059c8e7d2905b92.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/gradio/5c0ea9a1127c75807c002e88dc88285df1717565/tune1332setting13321.mid\n",
            "Fichero escrito:./uploads/tune1332setting13321.mid\n",
            "./uploads/tune1332setting13321.wav\n",
            "./uploads/tune1332setting13321.wav\n",
            "Downloading: 17% [1837137920 / 10288727721] bytes"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}